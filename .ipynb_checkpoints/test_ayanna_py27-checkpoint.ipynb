{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "from sklearn.metrics import average_precision_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./Data/emails.train.csv')\n",
    "text = train['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re_tokenizer = RegexpTokenizer(r'\\b[^\\d\\W]+\\b') # tokenize words that are not numbers\n",
    "mystopwords = set(stopwords.words('english')) # stop words remover\n",
    "extras = set(['_', 'subject']) # remove subject and _\n",
    "mystopwords.update(extras)\n",
    "#ps = PorterStemmer() # stemming words\n",
    "#stemmer = SnowballStemmer(\"english\") # stemming words\n",
    "lemmatizer = WordNetLemmatizer() # lemmatizing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## First, lemmatize and create list of words\n",
    "def lemma(df):\n",
    "    # lemmatize \n",
    "    for i, line in enumerate(df['text']): \n",
    "        newline = [] \n",
    "        words = line.split() \n",
    "        for word in words: \n",
    "            word = lemmatizer.lemmatize(word) \n",
    "            newline.append(word) \n",
    "        new = ' '.join(newline)  \n",
    "        df.loc[i, 'text'] = new # replace line at the index position with the new line that is the lemmatized words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## data\n",
    "train = pd.read_csv('./Data/emails.train.csv')\n",
    "test  = pd.read_csv('./Data/emails.test.csv')\n",
    "\n",
    "lemma(train)\n",
    "lemma(test)\n",
    "\n",
    "# for i in 10:\n",
    "\n",
    "# Get labels splitted set\n",
    "subtrain_X, subval_X = train_test_split(train, test_size = 0.25, )\n",
    "\n",
    "Y_train = train['spam']\n",
    "Y_test = test['spam']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=mystopwords, tokenizer=re_tokenizer.tokenize, max_features = 1000)\n",
    "vectorizer.fit(train['text'])\n",
    "\n",
    "X_train = vectorizer.transform(train['text']).todense() ## features\n",
    "X_test = vectorizer.transform(test['text']).todense() ## features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN model classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_k = list(range(1,50))\n",
    "\n",
    "# only odd numbers\n",
    "neighbor = filter(lambda x: x % 2 != 0, random_k)\n",
    "\n",
    "cross_scores = []\n",
    "\n",
    "# 10 fold crossvalidation using training set, to find optimal k-value for classifier\n",
    "for k in neighbor:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, Y_train, cv=10, scoring='accuracy')\n",
    "    cross_scores.append(scores.mean())\n",
    "\n",
    "# misclassification error\n",
    "MSE = [1 - x for x in cross_scores]\n",
    "optimal_k = neighbor[MSE.index(min(MSE))]\n",
    "print \"The optimal number of neighbors is %d\" % optimal_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot with MSE vs k\n",
    "plt.plot(neighbor, MSE)\n",
    "plt.xlabel('Number of Neighbors K')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with use of optimal_k\n",
    "knn = KNeighborsClassifier(n_neighbors= optimal_k)\n",
    "\n",
    "# model fitting\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "# predict\n",
    "Y_pred = knn.predict(X_test)\n",
    "\n",
    "# accuracy evaluation\n",
    "print accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "pd.DataFrame({\n",
    "    'id': test.id,\n",
    "    'spam': Y_pred\n",
    "}).to_csv('knn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_class = RandomForestClassifier() \n",
    " \n",
    "# Use a grid search to find optimal parameters\n",
    "param_grid = { \n",
    "           \"n_estimators\" : [8, 16, 32, 40, 48, 56],\n",
    "           \"max_depth\" : [1, 5, 10, 15, 20, 25],\n",
    "           \"min_samples_leaf\" : [1, 2, 4, 6, 8, 10]}\n",
    " \n",
    "CV_rf_class = GridSearchCV(estimator=rf_class, param_grid=param_grid, n_jobs=-1)\n",
    "CV_rf_class.fit(X_train, Y_train)\n",
    "print CV_rf_class.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print CV_rf_class.best_score_\n",
    "print accuracy_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est = grid_search.best_estimator_\n",
    "Y_pred = est.predict(X_test)\n",
    "\n",
    "pd.DataFrame({\n",
    "    'id': test.id,\n",
    "    'spam': Y_pred\n",
    "}).to_csv('rforest.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Gaussian Process Model Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaus_class = GaussianProcessClassifier()\n",
    "\n",
    "gaus_class.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = gaus_class.predict(X_test)\n",
    "\n",
    "print accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "pd.DataFrame({\n",
    "    'id': test.id,\n",
    "    'spam': Y_pred\n",
    "}).to_csv('gaussian.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
